# 爬虫程序：获取知乎“web”词条首页的所有问题和显示回答
作为大一学生，本次任务完全零基础，拿到题目以后先是恶补了一下从未接触过的Python语言，因为只花了两天时间看Python最基础的东西，所以很多语句在语法方面可能有更加便捷高效的用法，
  希望在这点上不要太影响本次任务的最终效果。之后开始学习关于HTML与HTTP的相关内容，并浏览了一些爬虫程序总体架构方面的知识，并上机操作练习。\
本程序一共有4个模块，分别为spider_main1, html_downloader1, html_parser1, html_outputer1，分别用于编写总调度程序，网页下载器，网页解析器和输出器。
由于进行本程序之前做过爬虫程序的练习，所以这些名称后都加了数字1作为区分。以下分别对每个模块做说明。

## 1 总控制程序 spider_main1
这个模块中包含了主函数。在类SpiderMain的构造方法中分别创建了另外三个模块中类的实例对象，在craw()方法中将三个类进行协调配合，
  也就是爬虫程序的运行流程：(1)网页下载器根据提供的需要爬取的url下载网页；(2)网页解析器将下载好的网页进行处理解析，得到我们需要的两类数据：关于
  “web”的提问以及相应显示的部分回答,并将这些数据传回craw()中；(3)这些爬取的数据将送至输出器收集，输出器将输出好的数据写入.html文件中。程序运行的结果是生成一个.html文件，该文件可以在浏览器中打开，并显示收集好的数据。
## 2 网页下载器 html_downloader1
这部分代码很简单，一个HtmlDowmloader类，一个简单的download()方法。重点是引入了urllib2，通过urlopen()方法，根据提供的url进行网页下载。
## 3 网页解析器 html_parser1
这部分代码要指明需要在网页上爬取的内容，重点有两个，一个是使用第三方插件BeautifulSoup，通过创建soup对象来实现相应功能，另一个是要掌握HTML标签的相关含义，以及如何通过审查元素的方法获取对应内容的标签格式。在类HtmlParser中，定义了parse()方法和_get_new_data()方法。parse()方法将下载好的网页进行解析，并调用本类的
  _get_new_data()方法，获取符合相应标签名和属性值的数据，parse()方法将获取到的这些数据返回。
## 4 输出器 html_outputer1
这部分代码就是为了输出文件。为了迎合web的形式，选取了.html类型的文件作为输出对象，以便在浏览器中打开。经测试在谷歌浏览器下显示正常，其他浏览器上可能会出现乱码。在这段程序的编写过程中，不知道算不算是我第一次真正的编写网页代码，因为用到了html的标签，以及通过<table>标签较好的输出每一个问题以及相应的显示回答。
  
此README随时保持更新和修改。
